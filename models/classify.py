import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models, transforms
from PIL import Image
import numpy as np
import cv2

from config import settings
from schemas import CnnResult, DiagnosisStatus, DiseaseType
from models.grad_cam import GradCamGenerator

class ClassifyModel:
    def __init__(self):
        print(f"ğŸ”„ Loading DenseNet model from {settings.MODEL_CNN_PATH}...")
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # åˆå§‹åŒ– DenseNet121 ä¸¦ä¿®æ”¹åˆ†é¡å±¤
        try:
            self.model = models.densenet121(weights=None)
        except:
            self.model = models.densenet121(pretrained=False)
            
        self.model.classifier = nn.Linear(self.model.classifier.in_features, 2)
        
        # è¼‰å…¥æ¬Šé‡
        checkpoint = torch.load(settings.MODEL_CNN_PATH, map_location=self.device)
        self.model.load_state_dict(checkpoint)
        self.model.to(self.device)
        self.model.eval()

        # é è™•ç†æµç¨‹
        self.preprocess_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

    def _resize_with_gray_padding(self, image, target_size=(224, 224)):
        """ ä¿æŒæ¯”ä¾‹ç¸®æ”¾ä¸¦è£œç°è‰²é‚Š"""
        h, w = image.shape[:2]
        target_w, target_h = target_size
        scale = min(target_w / w, target_h / h)
        new_w, new_h = int(w * scale), int(h * scale)
        
        resized_image = cv2.resize(image, (new_w, new_h))
        canvas = np.full((target_h, target_w, 3), 127, dtype=np.uint8)
        
        x_offset = (target_w - new_w) // 2
        y_offset = (target_h - new_h) // 2
        canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized_image
        return canvas

    def predict(self, crop_image: np.ndarray) -> CnnResult:
        # 1. é è™•ç†
        padded_img = self._resize_with_gray_padding(crop_image)
        pil_img = Image.fromarray(cv2.cvtColor(padded_img, cv2.COLOR_BGR2RGB))
        input_tensor = self.preprocess_transform(pil_img).unsqueeze(0).to(self.device)
        
        # 2. é–‹å•Ÿæ¢¯åº¦è¿½è¹¤ (ç‚ºäº† Grad-CAM)
        input_tensor.requires_grad_()
        
        # 3. å‰å‘å‚³æ’­ (æ‰‹å‹•åŸ·è¡Œ features å±¤ä»¥æ›è¼‰ hook)
        self.model.zero_grad()
        features = self.model.features(input_tensor)
        features.retain_grad() # é—œéµ hook
        
        out = F.relu(features, inplace=False)
        out = F.adaptive_avg_pool2d(out, (1, 1))
        out = torch.flatten(out, 1)
        outputs = self.model.classifier(out)
        probs = torch.sigmoid(outputs)[0]
        
        # 4. è§£æçµæœ
        p_cat = probs[0].item()
        p_conj = probs[1].item()
        
        if p_cat > p_conj:
            dominant_prob = p_cat
            disease_enum = DiseaseType.CATARACT
            target_idx = 0
        else:
            dominant_prob = p_conj
            disease_enum = DiseaseType.CONJUNCTIVITIS
            target_idx = 1
            
        # 5. åˆ¤å®šç‹€æ…‹ (é›™é‡é–¥å€¼)
        # ä½¿ç”¨è¨­å®šæª”ä¸­çš„é–¥å€¼
        if dominant_prob >= settings.AI_THRESH_HIGH:
            status = DiagnosisStatus.DETECTED
        elif dominant_prob >= settings.AI_THRESH_LOW:
            status = DiagnosisStatus.RISK
        else:
            status = DiagnosisStatus.NOT_DETECTED
            
        # 6. ç”Ÿæˆ Grad-CAM (åƒ… Risk/Detected éœ€è¦)
        heatmap_img = None
        if status in [DiagnosisStatus.RISK, DiagnosisStatus.DETECTED]:
            # åå‘å‚³æ’­è¨ˆç®—æ¢¯åº¦
            outputs[0, target_idx].backward()
            gradients = features.grad
            
            # ç”Ÿæˆç†±åŠ›åœ– (BGRæ ¼å¼)
            raw_heatmap = GradCamGenerator.generate(features, gradients, crop_image.shape[:2])
            
            # ç–ŠåŠ åœ–ç‰‡ (0.6 åŸåœ– + 0.4 ç†±åŠ›åœ–)
            # é€™è£¡æˆ‘å€‘å›å‚³ç–ŠåŠ å¥½çš„åœ–ï¼Œæ–¹ä¾¿ Service ç›´æ¥å­˜
            if raw_heatmap is not None:
                heatmap_img = cv2.addWeighted(crop_image, 0.6, raw_heatmap, 0.4, 0)

        return CnnResult(
            status=status,
            disease=disease_enum,
            confidence=dominant_prob,
            prob_cataract=p_cat,
            prob_conjunctivitis=p_conj,
            heatmap_image_url=None, # é€™è£¡å…ˆçµ¦ Noneï¼ŒService å±¤å­˜åœ–å¾Œæœƒå¡«å…¥
        ), heatmap_img # å¤šå›å‚³ä¸€å€‹ image data çµ¦ Service å­˜